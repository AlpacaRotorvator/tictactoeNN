{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.optimize import differential_evolution\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tic-Tac-Toe is a fairly easy to implement game. It's also fairly easy to play, which makes it a lot simpler to set up an AI capable of making valid(not necessarily good) plays.\n",
    "\n",
    "Here's the code for the game itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTTGame:\n",
    "    def __init__(self, players, size=3):\n",
    "        self.size = size\n",
    "        self.board = np.zeros((self.size, self.size))\n",
    "        self.curPlayer = -1\n",
    "        self.players = players\n",
    "        for i in range(len(self.players)):\n",
    "            #NN players need to know which symbol represents their plays in \n",
    "            #order to evaluate them\n",
    "            self.players[i].symbol = 2*i - 1\n",
    "        \n",
    "    def isValidMove(self, coords):\n",
    "        if self.board[coords] == 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def play(self):\n",
    "        curPlayerIdx = (self.curPlayer + 1) // 2\n",
    "        coords = self.players[curPlayerIdx].play(self.board)\n",
    "        if self.isValidMove(coords):\n",
    "            self.board[coords] = self.curPlayer\n",
    "            self.curPlayer *= -1\n",
    "            return 1\n",
    "        return 0\n",
    "    \n",
    "    #This is ugly, I know\n",
    "    #Returns the number corresponding to a player if he's the winner,\n",
    "    #two if there's no winner yet, or zero if there's neither a winner\n",
    "    #nor free slots to play in, ie. a tie(it can't tell in advance)\n",
    "    def checkWinner(self):\n",
    "        for i in self.board.sum(axis=0):\n",
    "            if int(np.abs(i) // self.size) != 0:\n",
    "                return i // self.size\n",
    "        for i in self.board.sum(axis=1):\n",
    "            if int(np.abs(i) // self.size) != 0:\n",
    "                return i // self.size\n",
    "        i = self.board.trace()\n",
    "        if int(np.abs(i) // self.size) != 0:\n",
    "            return i // self.size\n",
    "        i = self.board[::-1].trace()\n",
    "        if int(np.abs(i) // self.size) != 0:\n",
    "            return i // self.size\n",
    "        if self.board[self.board == 0].size == 0:\n",
    "            return 0\n",
    "        return 2\n",
    "    \n",
    "    def printBoard(self):\n",
    "        boardStr = [*map(lambda row:\n",
    "            [*map(lambda elem:\n",
    "                ({-1: \"O \", 0: \"_ \", 1:\"X \"})[elem]\n",
    "            , row)]\n",
    "        , self.board)]\n",
    "        boardStr = reduce(lambda row, res:\n",
    "            \"\".join(res) + \"\\n\" + \"\".join(row)\n",
    "        , boardStr, \"\")\n",
    "        print(boardStr)\n",
    "        \n",
    "    def reset(self):\n",
    "        self.__init__(self.players, self.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And an AI that simply chooses valid moves at random:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPlayer:\n",
    "    def play(self, board):\n",
    "        empty = np.where(board == 0)\n",
    "        randn = np.random.randint(0, empty[0].size)\n",
    "        coords = tuple([empty[0][randn], empty[1][randn]])\n",
    "        return coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally a single hidden layer neural network player:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNPlayer:\n",
    "    #This rather curious default sigmoid is actually tailored for backprop(cf. Lecun, 1998)\n",
    "    #will it work well in this differential evolution-backed problem? No idea.\n",
    "    #Throughout the code you'll also see me occasionally passing a ReLu activation function,\n",
    "    #I have not yet noticed any difference in performance, but ReLu should be\n",
    "    #cheaper to evaluate\n",
    "    def __init__(self, nNeurons, boardSize=3, \n",
    "                 sigmoid=lambda x: 1.7159 * np.tanh(2/3 * x), weights=None):\n",
    "        self.nNeurons = nNeurons\n",
    "        self.sigmoid = sigmoid\n",
    "        \n",
    "        self.nInputs = boardSize**2\n",
    "        self.hiddenLayerWeights = np.random.normal(size=(self.nNeurons,self.nInputs))\n",
    "        self.hiddenLayerBias = np.random.normal(size=(self.nNeurons, 1))\n",
    "        self.outputLayerWeights = np.random.normal(size=(1, self.nNeurons))\n",
    "        if weights is not None:\n",
    "            self.importWeightVector(weights)\n",
    "\n",
    "    def runNN(self, nNInput):\n",
    "        return np.dot(self.outputLayerWeights, \n",
    "                      self.sigmoid(np.dot(self.hiddenLayerWeights, nNInput) \n",
    "                                   + self.hiddenLayerBias))[0,0]\n",
    "    \n",
    "    def play(self, board):\n",
    "        #Instead of using 2D coordinates as inputs/outputs I flatten the board into an\n",
    "        #1D array both for simplicity and memory usage concerns.\n",
    "        ravelBoard = board.flatten()\n",
    "        emptyBoard = np.where(ravelBoard == 0)[0]\n",
    "        scores = []\n",
    "        for i in emptyBoard:\n",
    "            #The NN evaluates the worth of each play as if *it* would play there itself.\n",
    "            #In some experiments flipping the switch so it evaluates their worth in the\n",
    "            #eyes of the enemy instead improved performance significantly, but also \n",
    "            #hampered training times, for whatever reason.\n",
    "            ravelBoard[i] = self.symbol\n",
    "            scores.append(self.runNN(ravelBoard))\n",
    "            ravelBoard[i] = 0\n",
    "        scores = np.array(scores)\n",
    "        max_idx = emptyBoard[np.where(scores == scores.max())[0][0]]\n",
    "        res =  np.unravel_index(max_idx, board.shape)\n",
    "        return res\n",
    "    \n",
    "    def exportWeightVector(self):\n",
    "        return np.hstack((self.hiddenLayerWeights.ravel(), \n",
    "                          self.hiddenLayerBias.ravel(), \n",
    "                          self.outputLayerWeights.ravel()))\n",
    "    \n",
    "    def importWeightVector(self, weights):\n",
    "        #I should really do this based on the actual layer dimensions \n",
    "        #independently of the layers already being set-up or not\n",
    "        cuts = np.cumsum([self.hiddenLayerWeights.size, \\\n",
    "                          self.hiddenLayerBias.size, \\\n",
    "                          self.outputLayerWeights.size])\n",
    "        self.hiddenLayerWeights = weights[0:cuts[0]].reshape(self.hiddenLayerWeights.shape)\n",
    "        self.hiddenLayerBias = weights[cuts[0]:cuts[1]].reshape(self.hiddenLayerBias.shape)\n",
    "        self.outputLayerWeights = weights[cuts[1] :].reshape(self.outputLayerWeights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This helper function clashes two players a certain number of times and keeps track of winrates.\n",
    "\n",
    "It takes a number of games to run and a game instance(NN players must be properly initialized beforehand) as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playGame(game):\n",
    "    #print(\"Game {}\".format(i))\n",
    "    #game.printBoard()\n",
    "    while True:\n",
    "        game.play()\n",
    "        #game.printBoard()\n",
    "        if(game.checkWinner() != 2):\n",
    "            return game.checkWinner()\n",
    "    \n",
    "def nGames(Ngames, game):\n",
    "    wincount = []\n",
    "\n",
    "    for i in range(Ngames):\n",
    "        res = playGame(game)\n",
    "        wincount.append(res)\n",
    "        game.reset()\n",
    "        \n",
    "    return np.array(wincount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This trainer class trains a neural network with scipy's differential evolution implementation, using score in games against a random player as the cost function. It works, but I think it's possible to do better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNDETrainer:\n",
    "    def __init__(self, nNeurons, size=3, initialWeights=None):\n",
    "        self.size = size\n",
    "        self.nNplayer = NNPlayer(nNeurons, self.size)\n",
    "        self.game = TTTGame((self.nNplayer, RandomPlayer()), size)\n",
    "        if initialWeights is not None:\n",
    "            self.nNplayer.importWeightVector(initialWeights)\n",
    "\n",
    "    #The cost function here is a weighed average of the results of many\n",
    "    #games against a random player\n",
    "    def cost(self, weights):\n",
    "        self.nNplayer.importWeightVector(weights)\n",
    "\n",
    "        N = 25\n",
    "        wincount = nGames(N, self.game)\n",
    "        count = wincount.sum() / N\n",
    "        return -count\n",
    "\n",
    "    def trainDE(self):\n",
    "        bounds = np.array([(-1e6, 1e6)] * (self.nNplayer.hiddenLayerWeights.size \n",
    "                                       + self.nNplayer.hiddenLayerBias.size \n",
    "                                       + self.nNplayer.outputLayerWeights.size))\n",
    "        trainResults = differential_evolution(self.cost, bounds, tol = 0.5)\n",
    "        print(trainResults.message)\n",
    "        \n",
    "        if trainResults.success == True:\n",
    "            print(trainResults.nit)\n",
    "            print(trainResults.nfev)\n",
    "            return trainResults.x\n",
    "            \n",
    "        else:\n",
    "            print(\"Optimization failed somewhere\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a custom implementation of a genetic algorithm/DE along the lines of Wormington, M. *et al.*, \"Characterization of structures from X-ray scattering data using genetic algorithms\", which in turn is based on the original DE paper from Storn & Price that guided the Scipy implementation.\n",
    "\n",
    "Compared to scipy's DE implementation, which only lets me, at least as far as I can see, evaluate candidate solutions against random players, this implementation will let candidates clash among themselves thunderdome style. If not more performant at least this should prove vastly more exciting. This, however, also really complicates the design of the fitness/cost function, and we may be getting into snake oil territory here.\n",
    "\n",
    "One possible future improvement is letting NNs of various architectures(hidden layers numbers and sizes) participate in the training. I can see no way around this right now, however.\n",
    "\n",
    "Parameters to the constructor are the population size, number of neurons for the NNs, tic-tac-toe board size, mutation constant, recombination constant, maximum number of generations before the training automatically halts, number of games in a single trial sample and whether to output detailed performance information as the training progresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNGATrainer:\n",
    "    def __init__(self, popSize, nNeurons, boardSize=3, mutationConst=0.7,\n",
    "                 recombConst=0.5, maxGen=10, N=25, verbose=False):\n",
    "        self.curGen = 0\n",
    "        self.maxGen = maxGen\n",
    "        self.popSize = popSize\n",
    "        self.nNeurons = nNeurons\n",
    "        self.boardSize = boardSize\n",
    "        self.population = [NNPlayer(self.nNeurons, sigmoid=lambda x: np.fmax(0, x)) \\\n",
    "                            for x in range(self.popSize)]\n",
    "        self.scores = np.zeros(popSize)\n",
    "        self.trialsPassed = np.zeros(popSize)\n",
    "        self.mutationConst = mutationConst\n",
    "        self.recombConst = recombConst\n",
    "        self.N = N\n",
    "        self.verbose = verbose\n",
    "        self.randomTrialRatio = 0.25\n",
    "        \n",
    "        #Some constants to help reduce clutter. \n",
    "        #Should actually have been named n<...>TrialsPerGeneration, but this isn't Java.\n",
    "        self.nClashTrials = self.N * (self.popSize - 1)\n",
    "        self.nRandomTrials = int(np.ceil(self.randomTrialRatio * self.nClashTrials))\n",
    "        self.nTotalTrials = self.nClashTrials + self.nRandomTrials\n",
    "        \n",
    "    #This is a weird fitness function. Estimating the fitness of one candidate should\n",
    "    #necessarily alter the estimated fitness of the candidate it played against.\n",
    "    def crossClashFitness(self, traineeIdx):\n",
    "        fitnessScores = np.zeros(self.popSize)\n",
    "        for i in range(self.popSize):\n",
    "            if(i <= traineeIdx):\n",
    "                continue\n",
    "            \n",
    "            game = TTTGame((self.population[traineeIdx], self.population[i]), \n",
    "                           self.boardSize)\n",
    "            res = np.sum(nGames(self.N, game))\n",
    "            fitnessScores[traineeIdx] += -res\n",
    "            fitnessScores[i] += res\n",
    "            self.trialsPassed[i] += self.N\n",
    "            self.trialsPassed[traineeIdx] += self.N\n",
    "        return fitnessScores\n",
    "        \n",
    "    #Trials against a random player, lest we shall too much dwell in incest\n",
    "    #For now hardcoded so that at least 20% of total trials\n",
    "    #should be against a random player\n",
    "    def randomFitness(self, traineeIdx):\n",
    "        game = TTTGame((self.population[traineeIdx], RandomPlayer()), self.boardSize)\n",
    "        self.trialsPassed[traineeIdx] += self.nRandomTrials\n",
    "        return -np.sum(nGames(self.nRandomTrials, game))\n",
    "    \n",
    "    def updateAllScores(self):\n",
    "        for i in range(self.popSize):\n",
    "            self.scores += self.crossClashFitness(i)\n",
    "            self.scores[i] += self.randomFitness(i)\n",
    "    \n",
    "    #Use this before the first generation at your own risk.\n",
    "    def getNormalizedScores(self):\n",
    "        return self.scores / self.trialsPassed\n",
    "    \n",
    "    def trainStep(self):\n",
    "        if self.curGen == 0:\n",
    "            self.updateAllScores()\n",
    "        normScores = self.getNormalizedScores()\n",
    "        self.bestFitIdx = np.where(normScores == np.sort(normScores)[-1])[0][0]\n",
    "        self.bestFit = self.population[self.bestFitIdx].exportWeightVector()\n",
    "        self.curGen += 1\n",
    "        \n",
    "        for i in range(self.popSize):\n",
    "            mutant = self.genMutant()\n",
    "            contested = self.population[i].exportWeightVector()\n",
    "            trial = self.genTrial(mutant, contested)\n",
    "            \n",
    "            trialNN = NNPlayer(self.nNeurons, \n",
    "                               sigmoid=lambda x: np.fmax(0, x), weights=trial)\n",
    "            contestedNN = NNPlayer(self.nNeurons, \n",
    "                                   sigmoid=lambda x: np.fmax(0, x), weights=contested)\n",
    "            \n",
    "            trialScore = 0\n",
    "            trialTrials = 0\n",
    "            contestedScore = self.scores[i]\n",
    "            contestedTrials = self.trialsPassed[i]\n",
    "            \n",
    "            game = TTTGame((trialNN, RandomPlayer()), self.boardSize)\n",
    "            trialScore += -np.sum(nGames(self.nRandomTrials, game))\n",
    "            game = TTTGame((contestedNN, RandomPlayer()), self.boardSize)\n",
    "            contestedScore += -np.sum(nGames(self.nRandomTrials, game))\n",
    "            game = TTTGame((trialNN, contestedNN), self.boardSize)\n",
    "            clashRes = np.sum(nGames(self.nClashTrials, game))\n",
    "            trialScore += -clashRes\n",
    "            trialTrials += self.nRandomTrials + self.nClashTrials\n",
    "            contestedScore += clashRes\n",
    "            contestedTrials += self.nRandomTrials + self.nClashTrials\n",
    "            \n",
    "            trialNormScore = trialScore / trialTrials\n",
    "            contestedNormScore = contestedScore / contestedTrials\n",
    "            \n",
    "            \n",
    "            if (trialNormScore >= contestedNormScore):\n",
    "                self.population[i] = trialNN\n",
    "                self.scores[i] = trialScore\n",
    "                self.trialsPassed[i] = trialTrials\n",
    "                \n",
    "                if(trialNormScore \n",
    "                   >= self.scores[self.bestFitIdx] / self.trialsPassed[self.bestFitIdx]):\n",
    "                    self.bestFitIdx = i\n",
    "                    self.bestFit = trial\n",
    "            else:\n",
    "                self.scores[i] = contestedScore\n",
    "                self.trialsPassed[i] = contestedTrials\n",
    "        \n",
    "        if self.verbose:\n",
    "            self.printStats()\n",
    "        \n",
    "    def printStats(self):\n",
    "        normScores = self.getNormalizedScores()\n",
    "        print(\"Gen {:d}:\".format(self.curGen))\n",
    "        print(\"Raw Score:      Avg:{:.2f}\\tMax:{:.2f}\".format(self.scores.mean(),\n",
    "                                                      self.scores.max()))\n",
    "        print(\"Norm Score:     Avg:{:.2f}\\tMax:{:.2f}\".format(normScores.mean(),\n",
    "                                                      normScores.max()))\n",
    "        print(\"Trials:         Avg:{:.1f}\\tMax:{:.0f}\".format(self.trialsPassed.mean(),\n",
    "                                                      self.trialsPassed.max()))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "\n",
    "    def genMutant(self):\n",
    "        normScores = self.getNormalizedScores()\n",
    "        mutator1 = self.population[np.random.randint(0, self.popSize)].exportWeightVector()\n",
    "        mutator2 = self.population[np.random.randint(0, self.popSize)].exportWeightVector()\n",
    "        mutant = self.bestFit + self.mutationConst * (mutator1 - mutator2)\n",
    "        return mutant\n",
    "    \n",
    "    def genTrial(self, mutant, contested):\n",
    "        vecLen = mutant.size\n",
    "        trial = np.zeros(vecLen)\n",
    "\n",
    "        startIdx = np.random.randint(0, vecLen)\n",
    "        for i in range(startIdx, startIdx + vecLen):\n",
    "            if np.random.uniform() < self.recombConst:\n",
    "                trial[i % vecLen] = mutant[i % vecLen]\n",
    "            else:\n",
    "                trial[i % vecLen] = contested[i % vecLen]\n",
    "                \n",
    "        return trial\n",
    "    \n",
    "    def train(self):\n",
    "        while self.curGen < self.maxGen:\n",
    "            self.trainStep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With everything set up let's see how the AI fares against a random player:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5000\n",
    "nNeurons = 2\n",
    "nNPlayer = NNPlayer(nNeurons, sigmoid=lambda x: np.fmax(0, x))\n",
    "players = (nNPlayer, RandomPlayer())\n",
    "game = TTTGame(players)\n",
    "#nNPlayer.importWeightVector(np.fromfile(\"trainedvec.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wincount = nGames(N, game)\n",
    "labels, count = np.unique(wincount, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [*map(lambda x: {-1:\"Player 0\", 1:\"Player 1\", 0:\"Tie\"}[x], labels)]\n",
    "count = count / N\n",
    "plt.pie(count, labels=labels, autopct='%.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It probably did anywhere from not bad to abysmal right now. Let's train it for a while and see if it does better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = NNDETrainer(nNeurons, game.size, nNPlayer.exportWeightVector())\n",
    "res = trainer.trainDE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nNPlayer.importWeightVector(res)\n",
    "\n",
    "wincount= nGames(N, game)\n",
    "labels, count = np.unique(wincount, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [*map(lambda x: {-1:\"Player 0\", 1:\"Player 1\", 0:\"Tie\"}[x], labels)]\n",
    "count = count / N\n",
    "plt.pie(count, labels=labels, autopct='%.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This almost always better, but considering tic-tac-toe is a solved game, that's an awful lot of computation for little gain. Bummer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at what the custom implementation is capable of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gATrainer = NNGATrainer(10, 3, verbose=True)\n",
    "gATrainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = TTTGame((gATrainer.population[gATrainer.bestFitIdx], RandomPlayer()))\n",
    "N = 5000\n",
    "wincount= nGames(N, game)\n",
    "labels, count = np.unique(wincount, return_counts=True)\n",
    "labels = [*map(lambda x: {-1:\"Player 0\", 1:\"Player 1\", 0:\"Tie\"}[x], labels)]\n",
    "count = count / N\n",
    "plt.pie(count, labels=labels, autopct='%.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems good, huh?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stealth list of issues/developer diary mixed in the code:\n",
    "\n",
    "* ~~Currently raw scores are compared. This creates a bias in favour of older vectors, even when they are less performant. Maybe I should track the number of trials each vector has survived separatedly?~~\n",
    "\n",
    "* Right now every win/loss is treated the same, but maybe some weighting could be helpful? A possible implementation would be:\n",
    "\n",
    "\n",
    "1. At the beginning make every vector play N matches against a random player(this substitutes the current random trials?)\n",
    "\n",
    "2. Rank each vector according to its performance in this stage\n",
    "\n",
    "3. Distribute weights to each vector according to its rank(normalized weights?)\n",
    "\n",
    "4. Every win against a vector is now rescaled up according to its rank. Every loss is scaled down. Ties remain at zero?\n",
    "\n",
    "5. What to do about new vectors?\n",
    "\n",
    "\n",
    "* Make it multithreaded\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
